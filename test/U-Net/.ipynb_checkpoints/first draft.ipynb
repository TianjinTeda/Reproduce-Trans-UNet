{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "criminal-think",
   "metadata": {},
   "source": [
    "<center><font face=\"微软雅黑\" color=black size=10>TransUnet</font></center>  \n",
    "<center>*Xiangxie Zhang Goubi buzhidao ni xue hao!*<center>     \n",
    "<center> *Yicong Tan 5223245*<center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-muslim",
   "metadata": {},
   "source": [
    "\n",
    "![transunet](transunet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-guard",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\" color=black size=3>In our reproduction prjoect, we divide the code into three parts: </font>  \n",
    "The first part is dataloader, in which we load dataset and do data preprocessing, preparing them for thr traning.  \n",
    "The second part is model, in which we reproduce the TransUnet Model and provide a detail description of it.  \n",
    "The third part is training, in which we generally describe how we train the TransUnet and test it with testset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "light-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-affiliate",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\" color=black size=3>DataLoader </font>  \n",
    "In this part, Synapse_dataset inherit from  Dataset, which aims for loading image, performing preprocessing and transformation and forwarding it by getitem. This part is constructed for the first parameter of DataLoader."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-acting",
   "metadata": {},
   "source": [
    "Two rotate function for image augmentation.\n",
    "The first one rotates image 90*k degrees first, then flips it given random axis.  \n",
    "The second one rotates given random angle between (-20,20), the order parameter means the order of the spline interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adjustable-worcester",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_rot_flip(image, label):\n",
    "    k = np.random.randint(0, 4)\n",
    "    image = np.rot90(image, k)\n",
    "    label = np.rot90(label, k)\n",
    "    axis = np.random.randint(0, 2)\n",
    "    image = np.flip(image, axis=axis).copy()\n",
    "    label = np.flip(label, axis=axis).copy()\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def random_rotate(image, label):\n",
    "    angle = np.random.randint(-20, 20)\n",
    "    image = ndimage.rotate(image, angle, order=0, reshape=False)\n",
    "    label = ndimage.rotate(label, angle, order=0, reshape=False)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-metadata",
   "metadata": {},
   "source": [
    "In Pytorch, it is quite common for us to make some adjustment of input image by using torchvision.transforms. Transforms.Compose is to combine several actions , which will be used in trainer part. Here we could use some built-in functions of transform, like transforms.RandomCrop, transforms.Normalize,  transforms.ToTensor.   \n",
    "For more in [link]:https://pytorch.org/vision/stable/transforms.html. \n",
    "We could also personalize our own actions by implementing a call function of a class. This will make our class instance directly callable.  \n",
    "As shown below, RandomGenerator is such a class. It first gets image and label, which is actually two numpy ndarrays of original height and width of the data. Then it randomizes for two times given certain condition to perform rotation and flip. As we discussed, it is for the data augmentation.  \n",
    "After that, the array is zoomed using spline interpolation of the requested order. The input of resnet we used, requires for input size of (224, 224). Because of the integer attribute of label , 0 order( nearest interpolation) is used to protest this attribute.   \n",
    "Finally, we return the modified image and label of same dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "grand-schedule",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomGenerator(object):\n",
    "    def __init__(self, output_size):\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        if random.random() > 0.5:\n",
    "            image, label = random_rot_flip(image, label)\n",
    "        elif random.random() > 0.5:\n",
    "            image, label = random_rotate(image, label)\n",
    "        x, y = image.shape\n",
    "        if x != self.output_size[0] or y != self.output_size[1]:\n",
    "            image = zoom(image, (self.output_size[0] / x, self.output_size[1] / y), order=3)  # why not 3?\n",
    "            label = zoom(label, (self.output_size[0] / x, self.output_size[1] / y), order=0)\n",
    "        image = torch.from_numpy(image.astype(np.float32)).unsqueeze(0)\n",
    "        label = torch.from_numpy(label.astype(np.float32))\n",
    "        sample = {'image': image, 'label': label.long()}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-texture",
   "metadata": {},
   "source": [
    "Here it comes the Synapse_dataset, which helps us load data from dataset and conduct preprocessing using the above functions.  \n",
    "The annotation describes the function of each parameter.  \n",
    "In the getitem function, we first find name of each data given idx and concatenate the dir and filename. Then we load data using np.load or h5py.File. The data is contained in dictionary, in which  'image' and 'label' correponding to two numpy arrays.  \n",
    "Then we use transform function to do preprocessing and return constructed sample dictionary, which contains name, image, and label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "incoming-mileage",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Synapse_dataset(Dataset):\n",
    "    def __init__(self, base_dir, list_dir, split, transform=None):\n",
    "        self.transform = transform  # using transform in torch!\n",
    "        self.split = split # test_data or train_data\n",
    "        self.sample_list = open(os.path.join(list_dir, self.split+'.txt')).readlines()\n",
    "        #we first get name of each data_sample\n",
    "        self.data_dir = base_dir #dir of data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.split == \"train\":\n",
    "            slice_name = self.sample_list[idx].strip('\\n')\n",
    "            data_path = os.path.join(self.data_dir, slice_name+'.npz')\n",
    "            data = np.load(data_path)\n",
    "            image, label = data['image'], data['label']\n",
    "        else:\n",
    "            vol_name = self.sample_list[idx].strip('\\n')\n",
    "            filepath = self.data_dir + \"/{}.npy.h5\".format(vol_name)\n",
    "            data = h5py.File(filepath)\n",
    "            image, label = data['image'][:], data['label'][:]\n",
    "\n",
    "        sample = {'image': image, 'label': label}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        sample['case_name'] = self.sample_list[idx].strip('\\n')\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-paintball",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
